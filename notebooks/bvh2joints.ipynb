{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jason/repos/diffusion-motion-inbetweening\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convert.joints2bvh import BVH\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# animation = BVH.load(\"../../data/mixamo/0000_Breakdance_Freezes.bvh\")\n",
    "animation = BVH.load(\"save/results/condmdi_random_frames/condsamples000750000__benchmark_clip_T=30_CI=0_CRG=0_KGP=1.0_seed10/sample00_rep00_ik.bvh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((196, 22, 3), (196, 22))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animation.positions.shape, animation.rotations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The following is adapted from `motion_representation.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/repos/diffusion-motion-inbetweening/data_loaders/humanml/common/skeleton.py:2: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.5)\n",
      "  import scipy.ndimage.filters as filters\n"
     ]
    }
   ],
   "source": [
    "from data_loaders.humanml.common.skeleton import Skeleton\n",
    "import numpy as np\n",
    "import os\n",
    "from data_loaders.humanml.common.quaternion import (\n",
    "    qbetween_np,\n",
    "    qrot_np,\n",
    "    qmul_np,\n",
    "    qinv_np,\n",
    "    quaternion_to_cont6d_np,\n",
    "    qfix,\n",
    "    qrot,\n",
    "    qinv,\n",
    "    quaternion_to_cont6d,\n",
    ")\n",
    "from data_loaders.humanml.utils import paramUtil\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset specific globals\n",
    "joints_num = 22\n",
    "l_idx1, l_idx2 = 5, 8  # Lower legs\n",
    "fid_r, fid_l = [8, 11], [7, 10]  # Right/Left foot\n",
    "face_joint_indx = [2, 1, 17, 16]  # Facing direction, r_hip, l_hip, sdr_r, sdr_l\n",
    "r_hip, l_hip = 2, 1  # Hips\n",
    "feet_thre = 0.002\n",
    "\n",
    "data_dir = './dataset/'\n",
    "save_dir_joints = './dataset/HumanML3D_temp/new_joints/'\n",
    "save_dir_vecs = './dataset/HumanML3D_temp/new_joint_vecs/'\n",
    "# os.makedirs(save_dir_joints, exist_ok=True)\n",
    "# os.makedirs(save_dir_vecs, exist_ok=True)\n",
    "\n",
    "n_raw_offsets = torch.from_numpy(paramUtil.t2m_raw_offsets)\n",
    "kinematic_chain = paramUtil.t2m_kinematic_chain\n",
    "\n",
    "# Get offsets of target skeleton\n",
    "example_id = \"000021\"\n",
    "example_data = np.load(os.path.join(data_dir, example_id + '.npy'))\n",
    "example_data = example_data.reshape(len(example_data), -1, 3)\n",
    "example_data = torch.from_numpy(example_data)\n",
    "tgt_skel = Skeleton(n_raw_offsets, kinematic_chain, 'cpu')\n",
    "# (joints_num, 3)\n",
    "tgt_offsets = tgt_skel.get_offsets_joints(example_data[0])\n",
    "# print(tgt_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_skeleton(positions, target_offset):\n",
    "    src_skel = Skeleton(n_raw_offsets, kinematic_chain, 'cpu')\n",
    "    src_offset = src_skel.get_offsets_joints(torch.from_numpy(positions[0]))\n",
    "    src_offset = src_offset.numpy()\n",
    "    tgt_offset = target_offset.numpy()\n",
    "    # print(src_offset)\n",
    "    # print(tgt_offset)\n",
    "    '''Calculate Scale Ratio as the ratio of legs'''\n",
    "    src_leg_len = np.abs(src_offset[l_idx1]).max() + np.abs(src_offset[l_idx2]).max()\n",
    "    tgt_leg_len = np.abs(tgt_offset[l_idx1]).max() + np.abs(tgt_offset[l_idx2]).max()\n",
    "\n",
    "    scale_rt = tgt_leg_len / src_leg_len\n",
    "    # print(scale_rt)\n",
    "    src_root_pos = positions[:, 0]\n",
    "    tgt_root_pos = src_root_pos * scale_rt\n",
    "\n",
    "    '''Inverse Kinematics'''\n",
    "    quat_params = src_skel.inverse_kinematics_np(positions, face_joint_indx)\n",
    "    # print(quat_params.shape)\n",
    "\n",
    "    '''Forward Kinematics'''\n",
    "    src_skel.set_offset(target_offset)\n",
    "    new_joints = src_skel.forward_kinematics_np(quat_params, tgt_root_pos)\n",
    "    return new_joints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(positions, feet_thre):\n",
    "    # (seq_len, joints_num, 3)\n",
    "    #     '''Down Sample'''\n",
    "    #     positions = positions[::ds_num]\n",
    "\n",
    "    '''Uniform Skeleton'''\n",
    "    positions = uniform_skeleton(positions, tgt_offsets)\n",
    "\n",
    "    '''Put on Floor'''\n",
    "    floor_height = positions.min(axis=0).min(axis=0)[1]\n",
    "    positions[:, :, 1] -= floor_height\n",
    "\n",
    "    '''XZ at origin'''\n",
    "    root_pos_init = positions[0]\n",
    "    root_pose_init_xz = root_pos_init[0] * np.array([1, 0, 1])\n",
    "    positions = positions - root_pose_init_xz\n",
    "\n",
    "    # '''Move the first pose to origin '''\n",
    "    # root_pos_init = positions[0]\n",
    "    # positions = positions - root_pos_init[0]\n",
    "\n",
    "    '''All initially face Z+'''\n",
    "    r_hip, l_hip, sdr_r, sdr_l = face_joint_indx\n",
    "    across1 = root_pos_init[r_hip] - root_pos_init[l_hip]\n",
    "    across2 = root_pos_init[sdr_r] - root_pos_init[sdr_l]\n",
    "    across = across1 + across2\n",
    "    across = across / np.sqrt((across ** 2).sum(axis=-1))[..., np.newaxis]\n",
    "\n",
    "    # forward (3,), rotate around y-axis\n",
    "    forward_init = np.cross(np.array([[0, 1, 0]]), across, axis=-1)\n",
    "    # forward (3,)\n",
    "    forward_init = forward_init / np.sqrt((forward_init ** 2).sum(axis=-1))[..., np.newaxis]\n",
    "\n",
    "    target = np.array([[0, 0, 1]])\n",
    "    root_quat_init = qbetween_np(forward_init, target)\n",
    "    root_quat_init = np.ones(positions.shape[:-1] + (4,)) * root_quat_init\n",
    "\n",
    "    positions_b = positions.copy()\n",
    "\n",
    "    positions = qrot_np(root_quat_init, positions)\n",
    "\n",
    "    '''New ground truth positions'''\n",
    "    global_positions = positions.copy()\n",
    "\n",
    "    \"\"\" Get Foot Contacts \"\"\"\n",
    "    def foot_detect(positions, thres):\n",
    "        velfactor, heightfactor = np.array([thres, thres]), np.array([3.0, 2.0])\n",
    "\n",
    "        feet_l_x = (positions[1:, fid_l, 0] - positions[:-1, fid_l, 0]) ** 2\n",
    "        feet_l_y = (positions[1:, fid_l, 1] - positions[:-1, fid_l, 1]) ** 2\n",
    "        feet_l_z = (positions[1:, fid_l, 2] - positions[:-1, fid_l, 2]) ** 2\n",
    "        feet_l = ((feet_l_x + feet_l_y + feet_l_z) < velfactor).astype(np.float32)\n",
    "\n",
    "        feet_r_x = (positions[1:, fid_r, 0] - positions[:-1, fid_r, 0]) ** 2\n",
    "        feet_r_y = (positions[1:, fid_r, 1] - positions[:-1, fid_r, 1]) ** 2\n",
    "        feet_r_z = (positions[1:, fid_r, 2] - positions[:-1, fid_r, 2]) ** 2\n",
    "        feet_r = (((feet_r_x + feet_r_y + feet_r_z) < velfactor)).astype(np.float32)\n",
    "        return feet_l, feet_r\n",
    "\n",
    "    feet_l, feet_r = foot_detect(positions, feet_thre)\n",
    "\n",
    "    '''Quaternion and Cartesian representation'''\n",
    "    r_rot = None\n",
    "\n",
    "    def get_rifke(positions):\n",
    "        '''Local pose'''\n",
    "        positions[..., 0] -= positions[:, 0:1, 0]\n",
    "        positions[..., 2] -= positions[:, 0:1, 2]\n",
    "        '''All pose face Z+'''\n",
    "        positions = qrot_np(np.repeat(r_rot[:, None], positions.shape[1], axis=1), positions)\n",
    "        return positions\n",
    "\n",
    "    def get_cont6d_params(positions):\n",
    "        skel = Skeleton(n_raw_offsets, kinematic_chain, \"cpu\")\n",
    "        # (seq_len, joints_num, 4)\n",
    "        quat_params = skel.inverse_kinematics_np(positions, face_joint_indx, smooth_forward=True)\n",
    "\n",
    "        '''Quaternion to continuous 6D'''\n",
    "        cont_6d_params = quaternion_to_cont6d_np(quat_params)\n",
    "        # (seq_len, 4)\n",
    "        r_rot = quat_params[:, 0].copy()\n",
    "\n",
    "        '''Root Linear Velocity'''\n",
    "        # (seq_len - 1, 3)\n",
    "        velocity = (positions[1:, 0] - positions[:-1, 0]).copy()\n",
    "        velocity = qrot_np(r_rot[1:], velocity)\n",
    "\n",
    "        '''Root Angular Velocity'''\n",
    "        # (seq_len - 1, 4)\n",
    "        r_velocity = qmul_np(r_rot[1:], qinv_np(r_rot[:-1]))\n",
    "        # (seq_len, joints_num, 4)\n",
    "        return cont_6d_params, r_velocity, velocity, r_rot\n",
    "\n",
    "    cont_6d_params, r_velocity, velocity, r_rot = get_cont6d_params(positions)\n",
    "    positions = get_rifke(positions)\n",
    "\n",
    "    '''Root height'''\n",
    "    root_y = positions[:, 0, 1:2]\n",
    "\n",
    "    '''Root rotation and linear velocity'''\n",
    "    # (seq_len-1, 1) rotation velocity along y-axis\n",
    "    # (seq_len-1, 2) linear velovity on xz plane\n",
    "    r_velocity = np.arcsin(r_velocity[:, 2:3])\n",
    "    l_velocity = velocity[:, [0, 2]]\n",
    "    root_data = np.concatenate([r_velocity, l_velocity, root_y[:-1]], axis=-1)\n",
    "\n",
    "    '''Get Joint Rotation Representation'''\n",
    "    # (seq_len, (joints_num-1) *6) quaternion for skeleton joints\n",
    "    rot_data = cont_6d_params[:, 1:].reshape(len(cont_6d_params), -1)\n",
    "\n",
    "    '''Get Joint Rotation Invariant Position Represention'''\n",
    "    # (seq_len, (joints_num-1)*3) local joint position\n",
    "    ric_data = positions[:, 1:].reshape(len(positions), -1)\n",
    "\n",
    "    '''Get Joint Velocity Representation'''\n",
    "    # (seq_len-1, joints_num*3)\n",
    "    local_vel = qrot_np(np.repeat(r_rot[:-1, None], global_positions.shape[1], axis=1),\n",
    "                        global_positions[1:] - global_positions[:-1])\n",
    "    local_vel = local_vel.reshape(len(local_vel), -1)\n",
    "\n",
    "    data = root_data\n",
    "    data = np.concatenate([data, ric_data[:-1]], axis=-1)\n",
    "    data = np.concatenate([data, rot_data[:-1]], axis=-1)\n",
    "    data = np.concatenate([data, local_vel], axis=-1)\n",
    "    data = np.concatenate([data, feet_l, feet_r], axis=-1)\n",
    "\n",
    "    return data, global_positions, positions, l_velocity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover global angle and positions for rotation data\n",
    "# root_rot_velocity (B, seq_len, 1)\n",
    "# root_linear_velocity (B, seq_len, 2)\n",
    "# root_y (B, seq_len, 1)\n",
    "# ric_data (B, seq_len, (joint_num - 1)*3)\n",
    "# rot_data (B, seq_len, (joint_num - 1)*6)\n",
    "# local_velocity (B, seq_len, joint_num*3)\n",
    "# foot contact (B, seq_len, 4)\n",
    "def recover_root_rot_pos(data, return_rot_ang=False):\n",
    "    rot_vel = data[..., 0]\n",
    "    r_rot_ang = torch.zeros_like(rot_vel).to(data.device)\n",
    "    '''Get Y-axis rotation from rotation velocity'''\n",
    "    r_rot_ang[..., 1:] = rot_vel[..., :-1]\n",
    "    r_rot_ang = torch.cumsum(r_rot_ang, dim=-1)\n",
    "\n",
    "    r_rot_quat = torch.zeros(data.shape[:-1] + (4,)).to(data.device)\n",
    "    r_rot_quat[..., 0] = torch.cos(r_rot_ang)\n",
    "    r_rot_quat[..., 2] = torch.sin(r_rot_ang)\n",
    "\n",
    "    r_pos = torch.zeros(data.shape[:-1] + (3,)).to(data.device)\n",
    "    r_pos[..., 1:, [0, 2]] = data[..., :-1, 1:3]\n",
    "    '''Add Y-axis rotation to root position'''\n",
    "    r_pos = qrot(qinv(r_rot_quat), r_pos)\n",
    "\n",
    "    r_pos = torch.cumsum(r_pos, dim=-2)\n",
    "\n",
    "    r_pos[..., 1] = data[..., 3]\n",
    "\n",
    "    if return_rot_ang:\n",
    "        return r_rot_quat, r_pos, r_rot_ang\n",
    "    return r_rot_quat, r_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abs_data_from_joints(filepath: Path):\n",
    "    source_data = np.load(filepath)\n",
    "    f_frame, f_joints = source_data.shape[:2]\n",
    "    print(f\"Loaded file with {f_frame} frames and {f_joints} number of joints.\")\n",
    "    if f_joints > joints_num:\n",
    "        print(f\"Keeping only the first {joints_num} joints.\")\n",
    "        source_data = source_data[:, :joints_num]\n",
    "\n",
    "    ### compute absolute root information instead of relative, ignore rec_ric_data\n",
    "    rel_data, ground_positions, positions, l_velocity = process_file(source_data, 0.002)\n",
    "\n",
    "    r_rot_quat, r_pos, rot_ang = recover_root_rot_pos(torch.from_numpy(rel_data), return_rot_ang=True)\n",
    "    abs_data = rel_data.copy()\n",
    "    abs_data[:, 0] = rot_ang\n",
    "    abs_data[:, [1, 2]] = r_pos[:, [0,2]]\n",
    "\n",
    "    return abs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file with 154 frames and 52 number of joints.\n",
      "Keeping only the first 22 joints.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(153, 263)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_data = get_abs_data_from_joints(Path(\"../HumanML3D/joints/004185.npy\"))\n",
    "abs_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# TODO: GO ON HERE\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abs_data_from_bvh(filepath: Path):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condmdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
